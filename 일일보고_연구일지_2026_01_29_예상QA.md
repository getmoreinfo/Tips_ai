# 일일보고 연구일지 (2026-01-29) — 예상 Q&A

내일 코드·설계 관련해서 나올 수 있는 질문과 답변 초안입니다. 보고서 내용과 동일한 논리로 맞춰 두었습니다.

---

## 1. 모델·규모

### Q1. 왜 1.5B/3B가 아니라 7B로 올렸나요?

**A.**  
기존 1.5B/3B는 **수치 해석 중심 요약**에는 충분했지만, **리뷰 텍스트 기반 인사이트**(사용 시나리오·맥락 해석)를 넣었을 때 **문장 논리와 표현 다양성**에서 한계가 있었습니다. 그래서 **모델 규모 상승 = 기능 확장**(리뷰 맥락·실행 시사점까지 포함한 요약)이라는 목표로 7B로 확장했고, Colab A100 40GB로 7B 학습이 가능해져서 그 기준으로 맞췄습니다.

### Q2. 7B를 유지할지, 다시 3B로 내릴지 기준이 있나요?

**A.**  
네. **7B 유지**는 템플릿-only 대비 리뷰 기반 인사이트·실행 시사점에서 **일관된 품질 우위**가 나올 때입니다. **3B 등으로 축소**는 리소스(비용/GPU) 제약 대비 품질 차이가 크지 않다고 판단될 때 검토하고, **템플릿-only로 전환**은 JSON 오류·중첩 출력·언어 혼입이 잦거나, 모델 요약이 템플릿 대비 **명확한 우위**를 보이지 않을 때입니다. 그때는 운영 기본값을 템플릿 기반 요약으로 두는 걸 권장합니다.

---

## 2. 데이터·지표 해석

### Q3. 매출·점유율 숫자는 실제 거래 데이터인가요?

**A.**  
아닙니다. **실제 거래 데이터가 아니라**, **리뷰 수를 대리 지표(proxy)**로 쓴 **상대적 구조 해석** 결과입니다. 그래서 리포트 앞부분과 결과 해석 직전에 “매출·점유·성장 수치는 실제 거래를 의미하지 않는다”는 주의 문구를 넣었고, 소비자에게도 이 전제를 꼭 안내하는 걸 권장합니다.

### Q4. HHI 1279는 어떻게 해석하면 되나요?

**A.**  
**완전 분산 시장은 아니지만**, 특정 브랜드가 시장을 지배하는 수준도 아닌 **중간 정도의 집중도**를 의미합니다. 숫자를 모르는 독자도 “중간 수준 집중”이라고만 이해해도 됩니다.

### Q5. 3000 카테고리는 다 나오나요? 실제로 그만큼 쓰나요?

**A.**  
3000은 **확장을 고려한 상한값**입니다. **현재 데이터셋에서는 일부 카테고리만** 실제로 사용하고, 다나와 전체 카테고리 수를 넘지 않도록 상한만 넉넉히 둔 것입니다.

---

## 3. 학습·파이프라인

### Q6. LoRA rank 16, max_length 2048, batch 2로 한 이유는?

**A.**  
A100 40GB에서 **OOM을 피하기 위한 조정**입니다. `max_length=4096`이나 `lora_r=32`, 더 큰 batch를 쓰면 OOM이 나서, 40GB에 맞춰 2048·r=16·batch_size=2·grad_accum=16(effective 32)로 맞췄습니다. 80GB나 다른 GPU 쓰면 이 값들은 다시 조정할 수 있습니다.

### Q7. 학습 품질은 loss 말고 다른 지표로 봤나요?

**A.**  
**정성적으로** 봤습니다. 동일 카테고리 기준으로 7B는 3B 대비 **리뷰 텍스트 기반 실행 시사점 문장의 구체성**이 좋아졌고, **문단 논리 단절**이 줄어든 걸 확인했습니다. 수치 지표(예: JSON 오류율, 템플릿 vs 모델 비교)는 26번 평가·DB 연동 단계에서 보강할 예정입니다.

### Q8. 22 → 23 → 24만 쓰면 되나요? Colab에서 뭘 먼저 해야 하나요?

**A.**  
Colab에서는 (1) Drive 마운트 필요 시 선행, (2) Git clone/pull, (3) CSV 확인, (4) 패키지 설치 후 **22번(SFT JSONL) → 23번(LoRA 학습) → 24번(리포트 요약 생성)** 순서로 실행하면 됩니다. 자세한 명령·오류 대응은 `COLAB_RUN_ORDER.md`에 정리돼 있습니다.

---

## 4. 코드·구현

### Q9. 24번에서 토크나이저를 adapter가 아니라 base_model에서 로드하는 이유는?

**A.**  
adapter 디렉터리에는 **vocab 파일 등이 없을 수 있어** `vocab_file None` 같은 `TypeError`가 났습니다. PEFT adapter는 **메타데이터의 base_model**만 있으면 되므로, 토크나이저는 **`training_metadata.json`의 base_model**에서만 로드하고 adapter 경로는 제거해 두었습니다.

### Q10. 24번에서 JSON·중국어·`<|im_end|>` 제거하는 이유는?

**A.**  
모델이 **중첩 JSON**, **중국어 구간**, **`<|im_end|>` 토큰**을 그대로 출력하는 경우가 있어, 파싱 오류와 노출 문제가 생겼습니다. 그래서 **정규화 함수**로 중첩 해제·중국어 구간 제거·특수 토큰 제거 후 **한국어 요약만** 추출하도록 했습니다.

### Q11. 리뷰 텍스트 컬럼 이름이 CSV마다 다른데 어떻게 맞췄나요?

**A.**  
24번에서 **`review_text`, `review_content`, `content`, `text`, `body`** 등 여러 이름을 후보로 두고, 실제 CSV 컬럼과 매칭되도록 유연하게 인식하도록 해 두었습니다. 그래서 export 스크립트나 DB 스키마가 조금 달라도 동작하도록 했습니다.

### Q12. products_all.csv를 Git에 넣은 이유는?

**A.**  
Colab에서 **Git pull만으로** 코드와 데이터를 같이 받으려고요. 예전에는 `.gitignore`에 있어서 pull해도 CSV가 없어 22·24번이 실패하는 경우가 있었고, 그걸 막기 위해 저장소에 포함하도록 조정했습니다. 대용량이 부담이면 Drive 업로드 방식으로 대체 가능합니다.

---

## 5. 운영·다음 단계

### Q13. 백엔드에서는 템플릿과 모델 요약을 어떻게 쓸 계획인가요?

**A.**  
**템플릿 기반 요약을 기본값**으로 두고, **모델 출력은 선택 옵션**으로 두는 구조를 권장합니다. 모델이 JSON 오류·언어 혼입 등으로 불안정할 때는 템플릿만 쓰고, 품질이 안정되면 모델 요약을 노출하는 식으로 단계적으로 갈 수 있습니다. Node.js 백엔드에서는 25번(CSV 기반 리포트 생성) 또는 DB 직접 버전과 연동하면 됩니다.

### Q14. 다음에 뭘 할 예정인가요?

**A.**  
(1) 학습 결과 Drive/로컬 영구 보관, (2) 여러 카테고리·다수 카테고리로 24번 반복 실행해 품질·일관성 확인, (3) SFT 데이터·context length 확대 검토, (4) 백엔드 연동 및 위와 같은 운영 시나리오 확정입니다. 의사결정은 앞에서 말한 “7B 유지 / 3B 축소 / 템플릿-only 전환” 기준으로 합니다.

---

*위 답변은 `일일보고_연구일지_김민수_2026_01_29.md` 및 사용자가 정리한 최신 요약 구조를 기준으로 작성되었습니다. 회의 시 문맥에 맞게 짧게 말할 부분만 골라 쓰시면 됩니다.*
