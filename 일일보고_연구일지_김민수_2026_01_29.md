## 일일보고_연구일지_김민수_2026_01_29

### 주요 항목 요약

- **Colab 기반 학습·추론 파이프라인 전환**  
  - 로컬(Windows/맥) 대신 **Google Colab + A100 GPU**에서 Qwen2.5-7B LoRA 학습·리포트 요약 생성까지 수행  
  - 코드 동기화: 로컬에서 **Git push** → Colab에서 **Git pull** 후 동일 스크립트(22→23→24) 실행
- **학습량·기본값 A100 기준으로 상향**  
  - 베이스 모델: **Qwen/Qwen2.5-7B-Instruct**  
  - LoRA: `lora_r=16`, `lora_alpha=32`, `max_length=2048`, `batch_size=2`, `grad_accum=16`, `epochs=10` (A100 40GB OOM 방지)  
  - SFT 데이터: 카테고리당 **100샘플**, 최대 **3000카테고리**(상한값, 현재 데이터셋에서는 일부 카테고리만 실사용), **리뷰 텍스트 인사이트(use_review_text)** 기본 포함
- **24번 추론 안정화**  
  - 모델 출력 정규화: 중첩 JSON·중국어·`<|im_end|>` 제거, 한국어 요약만 추출  
  - 토크나이저: adapter 디렉터리 대신 **메타데이터의 base_model**에서 로드하여 `TypeError`(vocab_file None) 해소
- **리포트 요약 품질**  
  - 그림/동화/놀이책 카테고리 기준, **리뷰 수·HHI·평균 평점**과 함께 **리뷰 키워드·세그먼트·사용 시나리오**가 반영된 marketOverviewSummary 정상 생성 확인

> **※ 분석 해석 주의**  
> 본 리포트의 매출·점유·성장 수치는 **실제 거래 데이터를 의미하지 않으며**, 리뷰 수를 대리 지표(proxy)로 활용한 **상대적 구조 해석 결과**입니다. 오해 방지를 위해 리포트 소비자에게 위 전제를 명시할 것을 권장합니다.

---

### 1) Colab 전환 및 Git 동기화

#### 1-1. Colab 실행 흐름

- **환경**: Google Colab, 런타임 유형 **GPU(A100 40GB)**  
- **코드 공급**: GitHub 저장소 `getmoreinfo/ai-tr` **clone** 또는 **pull**  
  - 비공개 저장소인 경우 Personal Access Token을 URL에 포함해 clone  
  - 데이터: `products_all.csv`, `reviews_all.csv`는 저장소에 포함해 push/pull로 동기화 (또는 Drive 업로드)
- **실행 순서**  
  1. (선택) Drive 마운트 — 학습 결과 저장 시  
  2. Git clone 또는 pull  
  3. CSV 확인 (`products_all.csv`, `reviews_all.csv`)  
  4. 패키지 설치: `transformers`, `peft`, `datasets`, `accelerate`, `torch`, `bitsandbytes`, `pandas`  
  5. **22** SFT JSONL 생성  
  6. **23** LoRA 학습  
  7. (선택) 학습 결과 Drive 복사  
  8. **24** 리포트 요약 생성

#### 1-2. 문서 정리

- **COLAB_RUN_ORDER.md**: Colab에서 쳐야 할 명령어 순서·오류별 조치  
- **COLAB_FULL_PIPELINE.md**: 학습부터 검증까지 전체 파이프라인 단계  
- **COLAB_DIRECT_PASTE.md**: Drive/Git 없이 코드·파일만 Colab에 붙여넣어 실행하는 방식

---

### 2) 사용 모델·학습 기준 (Colab/A100)

#### 2-1. 7B로 확대한 이유 (전략적 정당화)

- 기존 1.5B/3B 모델은 **수치 해석 중심 요약**에는 충분했으나, **리뷰 텍스트 기반 인사이트**(사용 시나리오·맥락 해석)를 반영할 때 **문장 논리와 표현 다양성에서 한계**를 보였습니다.  
- 이를 보완하기 위해 **7B로 확장**하였으며, 즉 **모델 규모 상승 = 기능 확장**(리뷰 맥락·실행 시사점까지 포함한 요약)이라는 논리로 정당화합니다.  
- Colab A100 40GB 도입으로 7B 학습이 가능해졌고, OOM 방지를 위해 max_length·batch·lora_r 등은 40GB에 맞춰 조정했습니다.

#### 2-2. 모델 및 LoRA 설정

- **베이스 모델**: `Qwen/Qwen2.5-7B-Instruct`
- **LoRA**  
  - `lora_r=16`, `lora_alpha=32` (OOM 방지로 32→16 조정)  
  - `max_length=2048` (4096 시 OOM 발생하여 2048로 고정)  
  - `batch_size=2`, `grad_accum=16` → effective batch 32  
  - `epochs=10`, `lr=1e-4`, `warmup_ratio=0.05`  
  - `save_steps=500`, `save_total_limit=3`

#### 2-3. 학습 데이터(SFT)

- **생성 스크립트**: `22_prepare_report_summary_sft.py`  
- **기본값 변경**  
  - `samples_per_category=100`, `max_categories=3000`  
  - **3000 카테고리**는 향후 확장을 고려한 **상한값**이며, 현재 데이터셋에서는 일부 카테고리만 실사용됩니다.  
  - `use_review_text` 기본 **True** (리뷰 키워드·긍정/부정 예시 포함), 끄려면 `--no_use_review_text`  
- **실제 학습**: 400 examples, 10 epochs, 약 53분 소요, `train_loss` 수렴

---

### 3) 파이프라인·스크립트 변경

#### 3-1. 22_prepare_report_summary_sft.py

- SFT 데이터 “많이” 생성용 기본값  
  - `max_categories=3000`(상한), `samples_per_category=100`, `subsample_ratio=0.9`  
  - `use_review_text` 기본 True, `--no_use_review_text`로 비활성화

#### 3-2. 23_train_report_summary_lora.py

- A100 40GB 기준 기본값  
  - `base_model=Qwen/Qwen2.5-7B-Instruct`, `max_length=2048`, `epochs=10`  
  - `batch_size=2`, `grad_accum=16`, `lora_r=16`, `lora_alpha=32`  
  - `save_total_limit=3`, `warmup_ratio=0.05`  
- OOM 대비: 4096/32/4 → 2048/16/2로 조정

#### 3-3. 24_generate_report_summary.py

- **출력 정규화**  
  - `_normalize_result_obj`, `_clean_summary_text`: 중첩 JSON 해제, `<|im_end|>`·중국어 구간 제거, 한국어 요약만 추출  
  - 리뷰 텍스트 컬럼: `review_text` 외 `review_content`, `content`, `text`, `body` 등 유연 인식
- **토크나이저 로드**  
  - adapter 디렉터리에는 vocab 등이 없을 수 있어, **메타데이터의 base_model**에서만 로드 (adapter 경로 제거)
- **디버그 출력 제거**  
  - `[DEBUG] reviewInsights 포함됨/없음` 등 print 삭제

#### 3-4. 기타

- **.gitignore**: `products_all.csv` 주석 처리하여 저장소에 포함·Colab에서 pull로 사용
- **COLAB_DIRECT_PASTE.md**, **COLAB_FULL_PIPELINE.md** 추가

---

### 4) 결과 및 평가

> **※ 분석 해석 주의**  
> 본 리포트의 매출·점유·성장 수치는 **실제 거래 데이터를 의미하지 않으며**, 리뷰 수를 대리 지표(proxy)로 활용한 **상대적 구조 해석 결과**입니다.

#### 성과

- **Colab에서 22→23→24 풀 파이프라인 정상 완료**  
  - Git push/pull로 코드·CSV 동기화 후, A100에서 LoRA 학습 및 리포트 요약 생성까지 수행
- **리포트 요약 품질**  
  - 그림/동화/놀이책 카테고리에서 **대리 지표 전제**, **리뷰 기준 47.1%·HHI 1279·평균 4.7점** 반영  
  - **HHI 1279**는 완전 분산 시장은 아니지만, 특정 브랜드가 시장을 지배하는 구조는 아닌 **중간 수준의 집중도**를 의미하며, 숫자를 모르는 독자도 해석 가능하도록 요약 문장에 반영됨  
  - **5,871건 리뷰 텍스트**, **리뷰 키워드·세그먼트**(연령 3세부터, 아이, 저렴 등), **실행 시사점**(세부 세그먼트 포지셔닝, 리뷰 콘텐츠 설계)까지 포함된 marketOverviewSummary 생성
- **학습 품질 (Loss 외)**  
  - 동일 카테고리 기준, **7B 모델은 3B 대비** 리뷰 텍스트 기반 **실행 시사점 문장의 구체성이 개선**되었으며, **문단 논리 단절 빈도가 감소**함을 정성적으로 확인하였습니다. (수치 지표는 추후 26 평가 스크립트·DB 연동 시 보강 예정)
- **학습 안정성**  
  - OOM 수정 후 10 epochs 완료, 토크나이저 로드 방식 수정으로 24번 추론 오류 해소

#### 한계/이슈

- **Drive 미마운트·폴더 없음**  
  - Colab에서 `tips_ai_colab` 폴더/CSV 없을 때 cp 실패 → Drive 마운트 선행·폴더 생성 또는 Git에 CSV 포함해 pull로 해결
- **리뷰 수=0 / reviewInsights 없음**  
  - 해당 카테고리 product_id와 reviews CSV 매칭이 안 되거나, review_text 컬럼이 없을 때 발생 → CSV 구조·동일 export 사용 확인 필요
- **training_metadata.json의 base_model**  
  - 예전 3B 기준으로 저장된 경우 24에서 3B로 표시·로드될 수 있음 → 메타데이터를 7B로 수정하거나, 23 재실행으로 갱신

---

### 5) 다음 단계 계획

1. **학습 결과 영구 보관**  
   - Colab 런타임 종료 전 학습 결과 디렉터리를 Drive로 복사하거나, 로컬로 다운로드해 보관
2. **다른 카테고리·다수 카테고리 추론**  
   - 24번을 여러 `--category_contains`로 반복 실행해 품질·일관성 확인  
   - 26번(품질 평가)은 DB 기반이므로, Colab에서는 24 출력을 기준으로 수동 검증
3. **SFT 데이터·학습량 확대**  
   - 카테고리·샘플 수를 더 늘리거나, `max_length`를 4096으로 올릴 경우 A100 80GB 또는 batch_size=1 등으로 재조정
4. **백엔드 연동 및 운영 시나리오**  
   - 전일과 동일: Node.js 백엔드에서 25 또는 DB직접 버전 연동, **템플릿 기반 요약 + 모델 출력(선택)** 구조로 안정성·유연성 확보

#### 의사결정 기준 (언제/어떤 기준으로 다음 단계로 갈지)

- **7B를 유지할 기준**  
  - 리뷰 텍스트 기반 인사이트·실행 시사점이 템플릿-only 대비 **일관되게 구체적**이고, JSON 형식 준수율이 운영에 허용 가능한 수준일 때 7B LoRA를 기본 추론 모델로 유지
- **다시 3B(또는 더 작은 모델)로 내려갈 조건**  
  - 리소스(GPU/비용) 제약으로 7B 유지가 어렵거나, 7B 대비 품질 차이가 미미하다고 판단될 때 3B 등으로 축소 검토
- **템플릿-only 운영 전환 기준**  
  - **모델 요약이 템플릿 대비 일관성·해석력에서 명확한 우위를 보이지 않을 경우**, 또는 JSON 오류·중국어/중첩 출력 등이 잦을 경우, **운영 단계에서는 템플릿-only 모드를 기본값으로 유지**한다.  
  - 모델 출력은 참고/연구용으로만 활용하고, 고객 노출용은 템플릿 기반 요약을 사용하는 방안을 권장

---